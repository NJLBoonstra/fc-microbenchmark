{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation cell\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from os import path, listdir\n",
    "from collections import namedtuple\n",
    "from functools import reduce\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Use simpson's rule for calculating AUC\n",
    "from scipy.integrate import simpson\n",
    "\n",
    "from process_results import recursive_file_search, calculate_average_baselines, concurrency_histogram\n",
    "\n",
    "# https://gist.github.com/thriveth/8560036 color-blind friendly colors\n",
    "CB_color_cycle = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                  '#f781bf', '#a65628', '#984ea3',\n",
    "                  '#999999', '#e41a1c', '#dede00']\n",
    "\n",
    "# Set font settings globally\n",
    "font = {\n",
    "        \"family\": \"sans-serif\",\n",
    "        \"weight\": \"normal\",\n",
    "        \"size\": 12\n",
    "       }\n",
    "\n",
    "mpl.rc(\"font\", **font)\n",
    "\n",
    "mpl.rcParams['axes.prop_cycle'] = mpl.cycler(color=CB_color_cycle)\n",
    "\n",
    "# plt.rcParams['figure.constrained_layout.use'] = True\n",
    "# plt.xlim(xmin=0.0)\n",
    "\n",
    "RESULTS_DIR = path.abspath(\"../results\")\n",
    "\n",
    "def label_bars(bars, ax, customtxt = \"\", orientation=\"v\"):\n",
    "    for bar in bars:\n",
    "        if customtxt:\n",
    "            txt = customtxt\n",
    "        else:\n",
    "            if orientation == \"v\":\n",
    "                txt = bar.get_height()\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, txt)\n",
    "                xytxt = (0,1)\n",
    "                va=\"bottom\"\n",
    "                ha=\"center\"\n",
    "            else:\n",
    "                txt = bar.get_width()\n",
    "                xy=(txt, bar.get_y() + bar.get_height() / 2)\n",
    "                xytxt = (1,0)\n",
    "                va = \"center\"\n",
    "                ha = \"left\"\n",
    "                \n",
    "        max_chars = 6\n",
    "            \n",
    "        ax.annotate(f\"{txt}\"[:max_chars], \n",
    "                   xy=xy,\n",
    "                   xytext=xytxt,\n",
    "                   textcoords=\"offset points\",\n",
    "                   ha=ha, va=va)\n",
    "        \n",
    "def my_bar_plot(ax, values, groups, ylabel, datalabel, title=\"my bar plot\", orientation=\"v\"):\n",
    "    bar_width = 0.4\n",
    "    \n",
    "    # Set all labels\n",
    "    x_pos = np.arange(len(groups))\n",
    "    \n",
    "    if orientation == \"v\":\n",
    "        bartype = \"bar\"\n",
    "    else:\n",
    "        bartype = \"barh\"\n",
    "\n",
    "    barcall = getattr(ax, bartype)\n",
    "\n",
    "    if len(values) == 2 and len(datalabel) == 2:\n",
    "        my_bar = []\n",
    "        my_bar.append(barcall(x_pos - bar_width/2, values[0], bar_width, label=datalabel[0], rasterized=True))\n",
    "        my_bar.append(barcall(x_pos + bar_width/2, values[1], bar_width, label=datalabel[1], rasterized=True))\n",
    "    else:\n",
    "        my_bar = barcall(x_pos, values, bar_width, label=datalabel, rasterized=True)\n",
    "    \n",
    "\n",
    "#     if len(groups) > 1:\n",
    "#         max_value = max([subitem for item in values for subitem in item])\n",
    "#     else:\n",
    "#         max_value = max(values)\n",
    "        \n",
    "#     max_value = float(max_value)\n",
    "    \n",
    "    if orientation == \"v\":\n",
    "        ax.set_ylabel(ylabel)\n",
    "        ax.set_xticks(x_pos)\n",
    "        ax.set_xticklabels(groups)\n",
    "#         ax.set_ylim(ymax=max_value*1.1)\n",
    "    else:\n",
    "        ax.set_xlabel(ylabel)\n",
    "        ax.set_yticks(x_pos)\n",
    "        ax.set_yticklabels(groups)\n",
    "#         ax.set_xlim(xmax=max_value*1.1)\n",
    "    ax.legend(loc=\"lower left\", bbox_to_anchor=(0.0, 1.0), ncol=len(datalabel), borderaxespad=0, frameon=False)\n",
    "#     ax.set_title(title)\n",
    "\n",
    "    if isinstance(my_bar, list):\n",
    "        for bar in my_bar:\n",
    "            label_bars(bar, ax, orientation=orientation)\n",
    "    else:\n",
    "        label_bars(my_bar, ax, orientation=orientation)\n",
    "\n",
    "    return my_bar\n",
    "\n",
    "def save_my_figure(fig, figtype: str, machine: str, workload: str):\n",
    "    figure_loc = path.join(path.dirname(path.realpath(sys.argv[1])), machine, workload)\n",
    "\n",
    "    os.makedirs(figure_loc, exist_ok=True)\n",
    "    \n",
    "    figure_loc = path.join(figure_loc, figtype) + \".png\"\n",
    "    \n",
    "#     fig.set_size_inches(4,3)\n",
    "    fig.savefig(figure_loc, transparant=False, facecolor=\"w\", bbox_inches=\"tight\", dpi=300)\n",
    "    \n",
    "\n",
    "def find_baselines(x):\n",
    "    x = path.basename(x)\n",
    "    return x == \"baseline.txt\" or x == \"baselines.txt\"\n",
    "\n",
    "def round_to_largest_significant_num(x):\n",
    "    i = 0\n",
    "    while x > 10:\n",
    "        x = int(x/10)\n",
    "        i += 1\n",
    "        \n",
    "    return x * 10**i\n",
    "\n",
    "def my_execution_histogram(ax, runtimes, datalabel=\"\", xlabel=\"\", ylabel=\"Frequency\"):\n",
    "    assert isinstance(runtimes, pd.Series)\n",
    "    \n",
    "    min_runtime = runtimes.min()\n",
    "    max_runtime = runtimes.max()\n",
    "    \n",
    "#     bin_size = abs(max_runtime - min_runtime) / bin_count\n",
    "\n",
    "    per_25 = runtimes.quantile(0.25)\n",
    "    per_75 = runtimes.quantile(0.75)\n",
    "#     Freedmanâ€“Diaconis rule\n",
    "    bin_size = 2 * ((per_75 - per_25) / (len(runtimes)**(1/3)))\n",
    "    try:\n",
    "        bins = round((max_runtime - min_runtime) / bin_size)\n",
    "    except ValueError as e:\n",
    "        extra_msg = \"\\nAdditional information: \" \\\n",
    "                    f\"max_runtime = {max_runtime}, \" \\\n",
    "                    f\"min_runtime = {min_runtime}, \" \\\n",
    "                    f\"bin_size = {bin_size}\"\n",
    "        raise Exception(extra_msg) from e\n",
    "        \n",
    "        \n",
    "    ax.hist(runtimes, bins=bins, label=datalabel, alpha=0.5)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    \n",
    "#     ax.set_xlim(xmin=min_runtime, xmax=max_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data gathering cell\n",
    "\n",
    "# Find all results\n",
    "result_filter = lambda x: \"processed-\" in x\n",
    "prediction_filter = lambda x: \"predictions-\" in x\n",
    "\n",
    "all_results = list(recursive_file_search(RESULTS_DIR, result_filter))\n",
    "all_predictions = list(recursive_file_search(RESULTS_DIR, prediction_filter))\n",
    "\n",
    "result_prefix = path.commonprefix(all_results)\n",
    "\n",
    "\n",
    "all_results = list(map(lambda x: path.split(x), all_results))\n",
    "\n",
    "\n",
    "machine_workload_sched = dict()\n",
    "\n",
    "for (p, result) in all_results:\n",
    "    workload = result.replace(\"processed-results-\", \"\").replace(\".txt\", \"\")\n",
    "    \n",
    "    sched = p.replace(result_prefix, \"\")\n",
    "    sched_machine = sched.split(\"/\")[0]\n",
    "    sched = \"\".join([c for c in sched_machine if c.isupper()]) \n",
    "    machine = sched_machine.replace(sched, \"\")\n",
    "    \n",
    "    # We did not name the m510 by name when the first results came in\n",
    "    if machine == \"\":\n",
    "        machine = \"m510\"\n",
    "    \n",
    "    sysmon = path.join(p, f\"sysmon-{workload}.txt\")\n",
    "    # check for a sysmon file\n",
    "    if not path.exists(sysmon):\n",
    "        sysmon = None\n",
    "    else:\n",
    "        sysmon = pd.read_csv(sysmon, comment=\"#\", skipinitialspace=True)\n",
    "    \n",
    "    if machine not in machine_workload_sched:\n",
    "        machine_workload_sched[machine] = dict()\n",
    "    \n",
    "    if workload not in machine_workload_sched[machine]:\n",
    "        machine_workload_sched[machine][workload] = {\"results\": [], \"predictions\": dict()}\n",
    "    # Already storing the dataframes\n",
    "    # remove rows where tVM == tFC == 0, as that indicates a crashed Firecracker\n",
    "    # MOVE THIS TO process_results.py!\n",
    "    df = pd.read_csv(path.join(p, result), comment=\"#\", skipinitialspace=True)\n",
    "    \n",
    "    machine_workload_sched[machine][workload][\"results\"].append((sched, df, sysmon))\n",
    "    \n",
    "    try:\n",
    "        # In a try-block, as a StopIteration is raised when no next found\n",
    "        prediction = next( (p for p in all_predictions \n",
    "                            if p == path.join(result_prefix, sched_machine, f\"predictions-{workload}.txt\")\n",
    "                            ) , [None])\n",
    "    except:\n",
    "        prediction = None\n",
    "        \n",
    "    machine_workload_sched[machine][workload][\"predictions\"][sched] = prediction\n",
    "\n",
    "print(machine_workload_sched[\"c5n\"][\"poisson-12500-1hr-mem\"])\n",
    "\n",
    "# nice snippet from stackoverflow\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f%s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f%s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "\n",
    "from sys import getsizeof\n",
    "sizeof_fmt(getsizeof(pickle.dumps(machine_workload_sched)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concurrency histogram\n",
    "for machine in machine_workload_sched:\n",
    "    # Skip others for now\n",
    "#     if machine != \"c5n\":# and machine != \"apollo\":\n",
    "#         continue\n",
    "    \n",
    "    for workload in machine_workload_sched[machine]:\n",
    "            \n",
    "#         if workload != \"poisson-12500-1hr-mem\" and workload != \"poisson-50000-1hr-cpu\" and workload != \"poisson-25000-1hr-75cpu25mem\":\n",
    "#             continue\n",
    "\n",
    "        for sched, df, _ in machine_workload_sched[machine][workload][\"results\"]:\n",
    "            pred_df = machine_workload_sched[machine][workload][\"predictions\"][sched]\n",
    "            pred_df = pd.read_csv(pred_df, comment=\"#\", skipinitialspace=True)\n",
    "            \n",
    "            fig, ax = concurrency_histogram(df, pred_df, output=True, title=\"\")\n",
    "            \n",
    "            save_my_figure(fig, f\"concurrency-histogram-{sched}\", machine, workload)\n",
    "            \n",
    "            plt.close(fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# descriptive statistics cell\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "all_figs = []\n",
    "all_axes = []\n",
    "\n",
    "\n",
    "MIN_SEC = 60\n",
    "MIN_MSEC = MIN_SEC*1000\n",
    "HOUR_SEC  = 60*60\n",
    "HOUR_MSEC = HOUR_SEC*1000\n",
    "\n",
    "def my_maximal_cpu_usage(minute: float) -> float:\n",
    "    if minute >= 5.0 and minute <= 55.0:\n",
    "        # Between 5 and 55 minutes -> full CPU usage\n",
    "        return 100.0\n",
    "    elif minute >= 60.0:\n",
    "        return 0.0\n",
    "    elif minute <= 0.0:\n",
    "        return 0.0\n",
    "    elif minute < 5.0:\n",
    "        return min(44*minute - 4.8 * minute*minute, 100.0)\n",
    "    elif minute > 55.0:\n",
    "        return min(- 14640 + 532*minute - minute*minute * 4.8, 100.0)\n",
    "    \n",
    "ideal_usage_seconds = [i for i in range(0, HOUR_SEC + 1, 1)]\n",
    "ideal_usage = [my_maximal_cpu_usage(i / MIN_SEC) for i in ideal_usage_seconds]\n",
    "\n",
    "for machine in machine_workload_sched:\n",
    "#     # Skip others for now\n",
    "#     if machine != \"c5n\":# and machine != \"apollo\":\n",
    "#         continue\n",
    "        \n",
    "    cur_axes = []\n",
    "    cur_figs = []\n",
    "    \n",
    "    for workload in machine_workload_sched[machine]:\n",
    "#         # Skip others for now\n",
    "#         if workload != \"poisson-12500-1hr-mem\" and workload != \"poisson-50000-1hr-cpu\" and workload != \"poisson-25000-1hr-75cpu25mem\":\n",
    "#             continue\n",
    "\n",
    "        # lists for gathering the data\n",
    "        deltavm = []\n",
    "        deltafc = []\n",
    "        auc_sys = []\n",
    "        \n",
    "        # store the auc's of total sys cpu time and user cpu time\n",
    "        cpu_sys_user = []\n",
    "        cpu_usage_graph_data = []\n",
    "        runtimes = []\n",
    "\n",
    "        bar_width = 0.4\n",
    "\n",
    "        for result in machine_workload_sched[machine][workload][\"results\"]:\n",
    "            # collect some basic metrics\n",
    "            deltavm.append((result[0], result[1][\"d tVM\"].mean()))\n",
    "            deltafc.append((result[0], result[1][\"d tFC\"].mean()))\n",
    "            runtimes.append([result[0], result[1][\"end time\"].max()])\n",
    "            \n",
    "            # sysmon is not always present\n",
    "            if result[2] is not None:\n",
    "                # Normalize the sysmon times\n",
    "                result[2][\"t\"] = result[2][\"t\"] - result[2][\"t\"].min()\n",
    "                \n",
    "                # Use a tuple here, as sysmon readings are optional\n",
    "                # so we must know whether the result+sched has a sysmon\n",
    "                auc_sys.append((result[0], simpson(result[2][\"cpu_percentage\"], result[2][\"t\"])))\n",
    "                cpu_sys_user.append((result[0], simpson(result[2][\"cpu_system\"]), simpson(result[2][\"cpu_user\"])))\n",
    "                \n",
    "                cpu_usage_graph_data.append((result[0], result[2][\"t\"] - result[2][\"t\"][0], result[2][\"cpu_percentage\"]))\n",
    "#             else:\n",
    "#                 auc_sys.append((result[0], \"None\"))\n",
    "#                 cpu_sys_user.append(())\n",
    "                \n",
    "                \n",
    "        #Create figures\n",
    "        deltafig, deltaax = plt.subplots()\n",
    "        cur_axes.append(deltaax)\n",
    "        cur_figs.append((\"time-delta\", deltafig))\n",
    "        \n",
    "        my_bar_plot(deltaax, [ [x[1] for x in deltafc], [y[1] for y in deltavm] ], \n",
    "                    [s[0] for s in deltafc], \"Time delta (ms)\", [\"delta tFC\", \"delta tVM\"],\n",
    "                    f\"delta plot of {machine} {workload}\")\n",
    "        \n",
    "        # Set all for the sysmon plot (not always present)\n",
    "        if auc_sys:\n",
    "            sysfig, sysax = plt.subplots()\n",
    "            cur_axes.append(sysax)\n",
    "            cur_figs.append((\"AUC\", sysfig))\n",
    "\n",
    "            # Normalize the values by using the ideal\n",
    "            y_values = [val[1] for val in auc_sys]\n",
    "            \n",
    "            y_max = max(y_values)\n",
    "            \n",
    "            # Append 'ideal' AUC (100% usage over 1hr\n",
    "            y_ideal = 100.0 * HOUR_SEC\n",
    "#             y_values.append(y_ideal)\n",
    "#             auc_sys.append((\"Maximal usage\", y_ideal, HOUR_SEC))\n",
    "            \n",
    "#             def my_bar_plot(ax, values, groups, ylabel, datalabel, title=\"my bar plot\", orientation=\"v\"):\n",
    "\n",
    "            my_bar_plot(sysax, [ (y/y_ideal) * 100 for y in y_values ],\n",
    "                        [s[0] for s in auc_sys], \"Normalized CPU utilization (percentage)\",\n",
    "                        \"AUC\", f\"cpu auc {machine} {workload}\")\n",
    "            \n",
    "            sysax.get_legend().remove()\n",
    "        \n",
    "        # Create the bars with runtimes\n",
    "        runfig, runax = plt.subplots()\n",
    "        cur_figs.append((\"runtime\", runfig))\n",
    "        cur_axes.append(runax)\n",
    "        \n",
    "        # collect predicted runtimes\n",
    "        for i, lst in enumerate(runtimes):\n",
    "            pred = pd.read_csv(machine_workload_sched[machine][workload][\"predictions\"][lst[0]], comment=\"#\", skipinitialspace=True)\n",
    "            \n",
    "            pred_runtime = pred[\"pred. end time\"].max()\n",
    "            runtimes[i].append(pred_runtime)\n",
    "            \n",
    "        # Pick one prediction as the 'ideal' (no point in showing them all as they vary little)\n",
    "        ideal_time = reduce(lambda x, y: x + y, [prediction for _, _, prediction in runtimes]) / len(runtimes)\n",
    "        runtimes.append([\"Ideal\", ideal_time, ideal_time])\n",
    "\n",
    "        # Determine largest and smallest runtime\n",
    "        tmp = [runtime for _, runtime, _ in runtimes]\n",
    "        shortest_runtime = min(tmp) / MIN_MSEC\n",
    "        longest_runtime = max(tmp) / MIN_MSEC\n",
    "        del tmp\n",
    "    \n",
    "              \n",
    "        my_bar_plot(runax, [ ( (runtime / MIN_MSEC) ) for _, runtime, _ in runtimes],\n",
    "                    [s[0] for s in runtimes], \"Run-time (minutes)\", \"Runtime\",\n",
    "                    f\"runtimes {machine} {workload}\", \"h\")\n",
    "#         runax.margins(x=0.11)\n",
    "        runax.get_legend().remove()\n",
    "        runax.set_xlim(xmin=45)\n",
    "\n",
    "        cells = [[\"Scheduler\", \"Ratio\"] ]\n",
    "        cells = cells + [ [x[0], f\"{round((x[2]/x[1]), 3)}\"] for x in cpu_sys_user]\n",
    "        \n",
    "        for i, (sched, t, cpu_percentage) in enumerate(cpu_usage_graph_data):\n",
    "            # Plot usage figures\n",
    "            usage_fig, usage_ax = plt.subplots()\n",
    "            cur_figs.append((f\"cpu-util-{sched}\", usage_fig))\n",
    "#             cpu_usage_graph_data.append((\"Maximal usage\", pd.DataFrame(ideal_usage_seconds), pd.DataFrame(ideal_usage)))\n",
    "    \n",
    "            usage_ax.plot((t / MIN_SEC), cpu_percentage, linestyle=\"-\", linewidth=0.5, marker=\"\", label=sched, alpha=1.0)\n",
    "            usage_ax.set_ylabel(\"CPU utilisation (percentage)\")\n",
    "            usage_ax.set_xlabel(\"Time (minutes)\")\n",
    "        \n",
    "        \n",
    "        for ax in cur_axes:\n",
    "#             ax.margins(0.1)\n",
    "            ax.autoscale_view()\n",
    "            \n",
    "        for figtype, fig in cur_figs:\n",
    "            fig.tight_layout()\n",
    "            save_my_figure(fig, figtype, machine, workload)\n",
    "            plt.close(fig=fig)\n",
    "        \n",
    "        \n",
    "        \n",
    "    all_axes = all_axes + cur_axes\n",
    "    all_figs = all_figs + [f[1] for f in cur_figs]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# numerical analysis cell\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "data_tuple = namedtuple(\"data\", [\"scheduler\", \"variance_tFC\", \"variance_tVM\", \"cvar_tFC\", \"cvar_tVM\", \"ratio_tFC_tVM\"])\n",
    "\n",
    "\n",
    "for machine in machine_workload_sched:\n",
    "#     # Skip others for now\n",
    "#     if machine != \"c5n\":# and machine != \"apollo\":\n",
    "#         continue\n",
    "        \n",
    "    cur_axes = []\n",
    "    cur_figs = []\n",
    "    \n",
    "    for workload in machine_workload_sched[machine]:\n",
    "            \n",
    "#         if workload != \"poisson-12500-1hr-mem\" and workload != \"poisson-50000-1hr-cpu\" and workload != \"poisson-25000-1hr-75cpu25mem\":\n",
    "#             continue\n",
    "            \n",
    "        data = []\n",
    "        \n",
    "        fig_var, ax_var = plt.subplots()\n",
    "        \n",
    "        for sched, df, _ in machine_workload_sched[machine][workload][\"results\"]:\n",
    "            # we pick a (workloadid, argument) tuple\n",
    "            wid, arg = -1, -1\n",
    "            if \"mem\" in workload:\n",
    "                wid, arg = 2, 20\n",
    "            elif \"cpu\" in workload:\n",
    "                wid, arg = 0,5500000\n",
    "                \n",
    "            df = df[ (df[\"workloadID\"] == wid) & (df[\"workload argument\"] == arg)]\n",
    "            \n",
    "#             for i, lst in enumerate(runtimes):\n",
    "#                 pred = pd.read_csv(machine_workload_sched[machine][workload][\"predictions\"][lst[0]], comment=\"#\", skipinitialspace=True)\n",
    "#                 pred = pred[ (pred[\"workloadID\"] == wid) & (pred[\"workload argument\"] == arg) ]\n",
    "                \n",
    "            #Calculate the variance between each execution of wid, arg\n",
    "            var_tFC = df[\"tFC\"].var()\n",
    "            var_tVM = df[\"tVM\"].var()\n",
    "            \n",
    "            std_tFC = df[\"tFC\"].std()\n",
    "            std_tVM = df[\"tVM\"].std()\n",
    "            mean_tFC = df[\"tFC\"].mean()\n",
    "            mean_tVM = df[\"tVM\"].mean()\n",
    "            \n",
    "            cvar_tFC = std_tFC / mean_tFC\n",
    "            cvar_tVM = std_tVM / mean_tVM\n",
    "\n",
    "            ratio = df[\"tFC\"].mean() / df[\"tVM\"].mean()\n",
    "\n",
    "            data.append(data_tuple(scheduler=sched, variance_tFC=var_tFC, variance_tVM=var_tVM, cvar_tFC=cvar_tFC, cvar_tVM=cvar_tVM, ratio_tFC_tVM=ratio))\n",
    "            \n",
    "        print(workload, data)\n",
    "        my_bar_plot(ax_var, [ [d.cvar_tFC for d in data], [d.cvar_tVM for d in data] ], \n",
    "                    [d.scheduler for d in data], \"Coefficient of variation\", [\"tFC\", \"tVM\"])\n",
    "        save_my_figure(fig_var, \"co-var\", machine, workload)\n",
    "        \n",
    "    plt.close(fig=fig_var)\n",
    "        \n",
    "    \n",
    "# for workload in machine_workload_sched[\"c5n\"]:\n",
    "#     print(f\"{workload}\")\n",
    "#     headers = data_tuple._fields\n",
    "#     print(\" \\t \".join(headers))\n",
    "\n",
    "#     for res in tmp[\"c5n\"][workload]:\n",
    "#         for i, field in enumerate(res):\n",
    "#             #Not rounding properly, but I don't mind for this preliminary result\n",
    "#             s = str(field)[0:len(headers[i])]\n",
    "#             spaces = len(headers[i]) - len(s)\n",
    "#             if spaces > 0:\n",
    "#                 s = s + \"\".join(\" \" for i in range(spaces))\n",
    "#             print(f\"{s} \\t \", end=\"\")\n",
    "#         print(\"\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#  Plot runtimes of each equal (workloadID, workload_argument)\n",
    "\n",
    "for machine in machine_workload_sched:\n",
    "        \n",
    "    cur_axes = []\n",
    "    cur_figs = []\n",
    "    \n",
    "    for workload in machine_workload_sched[machine]:\n",
    "            \n",
    "        data = []\n",
    "        \n",
    "        # Aggregate all schedulers in one figure\n",
    "        fig_t_fc, ax_fc = plt.subplots()\n",
    "        fig_t_vm, ax_vm = plt.subplots()\n",
    "        fig_h_fc, hg_fc = plt.subplots()\n",
    "        fig_h_vm, hg_vm = plt.subplots()\n",
    "        \n",
    "        all_axes = [\n",
    "                    (ax_vm, \"graph\"),\n",
    "                    (ax_fc, \"graph\"),\n",
    "                    (hg_vm, \"histo\"),\n",
    "                    (hg_fc, \"histo\")\n",
    "                   ]\n",
    "        all_figs = [\n",
    "                    (fig_t_fc, \"individual-runtimes-fc\"),\n",
    "                    (fig_t_vm, \"individual-runtimes-vm\"),\n",
    "                    (fig_h_fc, \"individual-rt-hist-fc\"),\n",
    "                    (fig_h_vm, \"individual-rt-hist-vm\"),]\n",
    "        \n",
    "        # Collect baseline values for tVM and tFC\n",
    "        baseline_paths = []\n",
    "        for sched in machine_workload_sched[machine][workload][\"predictions\"]:\n",
    "            basepath = path.dirname(machine_workload_sched[machine][workload][\"predictions\"][sched])\n",
    "            \n",
    "            baselines = recursive_file_search(basepath, find_baselines)\n",
    "            baseline_paths += baselines\n",
    "            \n",
    "        avg_baselines = calculate_average_baselines(files=baseline_paths)\n",
    "        \n",
    "        print(f\"{machine} {workload}\")\n",
    "        # TODO: Change the drawing order, such that the lowest values on the y axis are visible\n",
    "        for sched, df, df_sysmon in machine_workload_sched[machine][workload][\"results\"]:         \n",
    "            wid, arg = -1, -1\n",
    "            if \"mem\" in workload:\n",
    "                wid, arg = 2, 20\n",
    "            elif \"cpu\" in workload:\n",
    "                wid, arg = 0,5500000\n",
    "                \n",
    "            df = df[ (df[\"workloadID\"] == wid) & (df[\"workload argument\"] == arg)]\n",
    "            \n",
    "            # plot the runtimes for each measured run-time\n",
    "            ax_vm.plot(df.index, df[\"tVM\"], label=sched, alpha=0.5)\n",
    "            ax_fc.plot(df.index, df[\"tFC\"], label=sched, alpha=0.5)\n",
    "            \n",
    "            # Plot the histograms\n",
    "            try:\n",
    "                my_execution_histogram(hg_vm, df[\"tVM\"], sched, \"tVM (milliseconds)\")\n",
    "                my_execution_histogram(hg_fc, df[\"tFC\"], sched, \"tFC (milliseconds)\")\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(machine, workload, sched)\n",
    "                raise e\n",
    "            \n",
    "            \n",
    "        bl_fc, bl_vm = avg_baselines[wid][arg]\n",
    "        ax_vm.axhline(bl_vm, label=\"Baseline\")\n",
    "#         ax_vm.set_ylim(ymin=round_to_largest_significant_num(bl_vm))\n",
    "        ax_fc.axhline(bl_fc, label=\"Baseline\")    \n",
    "#         ax_fc.set_ylim(ymin=round_to_largest_significant_num(bl_fc))\n",
    "\n",
    "        for ax, ax_type in all_axes:\n",
    "            ax.legend()\n",
    "            if ax_type == \"graph\":\n",
    "                ax.set_xlabel(\"# instance\")\n",
    "                ax.set_ylabel(\"Time (ms)\")\n",
    "            elif ax_type == \"histo\":\n",
    "                ax.set_xlabel(\"Time (ms)\")\n",
    "                ax.set_ylabel(\"Frequency\")\n",
    "            \n",
    "        for fig, figtype in all_figs:\n",
    "            fig.tight_layout()\n",
    "            save_my_figure(fig, figtype, machine, workload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Create insets of the unclear plots of above\n",
    "machine = \"c5n\"\n",
    "workload = \"poisson-25000-1hr-75cpu25mem\"\n",
    "\n",
    "inset_fig, hg_ax = plt.subplots()\n",
    "inset_ax = hg_ax.inset_axes([0.2,0.1,0.75,0.85])\n",
    "\n",
    "for sched, df, df_sysmon in machine_workload_sched[machine][workload][\"results\"]:  \n",
    "    wid, arg = -1, -1\n",
    "    if \"mem\" in workload:\n",
    "        wid, arg = 2, 20\n",
    "    elif \"cpu\" in workload:\n",
    "        wid, arg = 0,5500000\n",
    "\n",
    "    \n",
    "\n",
    "    df = df[ (df[\"workloadID\"] == wid) & (df[\"workload argument\"] == arg)]\n",
    "    my_execution_histogram(hg_ax, df[\"tFC\"], sched, \"tFC (milliseconds)\")\n",
    "    my_execution_histogram(inset_ax, df[\"tFC\"], \"\", \"\")\n",
    "\n",
    "inset_ax.set_xlim(3900,5000)\n",
    "inset_ax.set_ylim(0,80)\n",
    "inset_ax.set_ylabel(\"\")\n",
    "inset_ax.set_xticklabels(\"\")\n",
    "inset_ax.set_yticklabels(\"\")\n",
    "\n",
    "hg_ax.legend()\n",
    "hg_ax.indicate_inset_zoom(inset_ax, edgecolor=\"black\")\n",
    "hg_ax.set_xlabel(\"Time (ms)\")\n",
    "hg_ax.set_ylabel(\"Frequency\")\n",
    "\n",
    "\n",
    "save_my_figure(inset_fig, \"inset-individual-rt-hist-fc\", machine, workload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
